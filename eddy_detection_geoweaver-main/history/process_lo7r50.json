[{
  "history_id" : "GmOzshID7gPC",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\n\n#from eddy_import import *\nimport os\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\nprint('logger start')\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\n\nprint('logger middle')\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)\n\nprint('logger end')",
  "history_output" : "",
  "history_begin_time" : 1670338222062,
  "history_end_time" : 1670338224378,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "K7shYh6Icqk0",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\n\n#from eddy_import import *\nimport os\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\nprint('logger start')\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\n\nprint('logger middle')\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)\n\nprint('logger end')",
  "history_output" : "",
  "history_begin_time" : 1670337976290,
  "history_end_time" : 1670337978592,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "BjsQ2Lq48oIG",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\n\n#from eddy_import import *\nimport os\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "",
  "history_begin_time" : 1670337886042,
  "history_end_time" : 1670337888039,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "G7TgRVhtvT4W",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\n#from eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/G7TgRVhtvT4W/tensorboard_logger.py\", line 8, in <module>\n    tensorboard_dir = os.path.join(\nNameError: name 'os' is not defined\n",
  "history_begin_time" : 1670337849891,
  "history_end_time" : 1670337851768,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "3lhnBj8YEQzc",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n",
  "history_begin_time" : 1670337836118,
  "history_end_time" : 1670337841069,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "q5j50cv5akc",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n",
  "history_begin_time" : 1670331413686,
  "history_end_time" : 1670331421503,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "2kipipmt2g7",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n",
  "history_begin_time" : 1669994031279,
  "history_end_time" : 1669994038319,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "Ob9rASPpsCLC",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "==============================================================================\nWriting Tensorboard logs to /Users/lakshmichetana/tensorboard/2022-10-30_21-49\n==============================================================================\n",
  "history_begin_time" : 1667180939217,
  "history_end_time" : 1667180944802,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "pho6XxAfjJLm",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "==============================================================================\nWriting Tensorboard logs to /Users/lakshmichetana/tensorboard/2022-10-18_08-59\n==============================================================================\n",
  "history_begin_time" : 1666097939515,
  "history_end_time" : 1666097946218,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "hqjmg9ox8tu",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/hqjmg9ox8tu/tensorboard_logger.py\", line 6, in <module>\n    from torch.utils.tensorboard import SummaryWriter\nModuleNotFoundError: No module named 'torch'\n",
  "history_begin_time" : 1665015471879,
  "history_end_time" : 1665015474008,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "gnjh13c68lu",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/gnjh13c68lu/tensorboard_logger.py\", line 6, in <module>\n    from torch.utils.tensorboard import SummaryWriter\nModuleNotFoundError: No module named 'torch'\n",
  "history_begin_time" : 1664976259934,
  "history_end_time" : 1664976261963,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "12akpwhdb48",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/12akpwhdb48/tensorboard_logger.py\", line 6, in <module>\n    from torch.utils.tensorboard import SummaryWriter\nModuleNotFoundError: No module named 'torch'\n",
  "history_begin_time" : 1664976160678,
  "history_end_time" : 1664976162882,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "kxtabgeduwz",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "======================================================================\nWriting Tensorboard logs to C:\\Users\\user\\tensorboard\\2022-09-28_09-31\n======================================================================\n",
  "history_begin_time" : 1664371856241,
  "history_end_time" : 1664371871342,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ikbaa6kza2u",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "Cannot run program \"python3.8\" (in directory \"C:\\Users\\user\\gw-workspace\\ikbaa6kza2u\"): CreateProcess error=2, The system cannot find the file specified",
  "history_begin_time" : 1664371261514,
  "history_end_time" : 1664371262086,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "vzx7edw2ewn",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "======================================================================\nWriting Tensorboard logs to C:\\Users\\user\\tensorboard\\2022-09-28_09-18\n======================================================================\n",
  "history_begin_time" : 1664371098670,
  "history_end_time" : 1664371110856,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "vonjt99pane",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "======================================================================\nWriting Tensorboard logs to C:\\Users\\user\\tensorboard\\2022-09-28_09-12\n======================================================================\n",
  "history_begin_time" : 1664370726449,
  "history_end_time" : 1664370737791,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0kqwzfkpydl",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "======================================================================\nWriting Tensorboard logs to C:\\Users\\user\\tensorboard\\2022-09-28_07-25\n======================================================================\n",
  "history_begin_time" : 1664364295424,
  "history_end_time" : 1664364306906,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "4unxhydkz15",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "======================================================================\nWriting Tensorboard logs to C:\\Users\\user\\tensorboard\\2022-09-27_16-19\n======================================================================\n",
  "history_begin_time" : 1664309987826,
  "history_end_time" : 1664309997623,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "adf51g2jchz",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "======================================================================\nWriting Tensorboard logs to C:\\Users\\user\\tensorboard\\2022-09-27_15-00\n======================================================================\n",
  "history_begin_time" : 1664305200452,
  "history_end_time" : 1664305214786,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "l96cat3pwaf",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "======================================================================\nWriting Tensorboard logs to C:\\Users\\user\\tensorboard\\2022-09-27_08-14\n======================================================================\n",
  "history_begin_time" : 1664280878915,
  "history_end_time" : 1664280888197,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "t8gf6rx0j3o",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "======================================================================\nWriting Tensorboard logs to C:\\Users\\user\\tensorboard\\2022-09-27_07-58\n======================================================================\n",
  "history_begin_time" : 1664279903230,
  "history_end_time" : 1664279913419,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hixxbxv189p",
  "history_input" : "import datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "Cannot run program \"python3.8\" (in directory \"C:\\Users\\user\\gw-workspace\\hixxbxv189p\"): CreateProcess error=2, The system cannot find the file specified",
  "history_begin_time" : 1663038346372,
  "history_end_time" : 1663038347340,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "llyracmieuv",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664372084804,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "b57sn4hb74p",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664373326982,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "xsvxqrz8mpf",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664280754606,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "gwbj3y9kv6z",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1664280754618,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "52gfq4pz956",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665096317652,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "tqe4tyntlg0",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665244616254,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "b3kimfd79ae",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665245508265,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "0yy5c5xon1w",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665253906559,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "31s07hd72s6",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665454136897,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "24sxwbf7nku",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665492179697,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "8q9h8ue5iup",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1665757921494,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Stopped"
},]
