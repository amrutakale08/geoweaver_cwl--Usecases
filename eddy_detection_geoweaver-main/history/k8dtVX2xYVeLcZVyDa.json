[{
  "history_id" : "z9lr9wfv7fv",
  "history_input" : "#Importing required libraries, inserting the system paths, fixing manual seeds for reproducibility\nfrom eddy_import import *\nimport os\nimport sys\nsys.path.insert(0, os.path.dirname(os.getcwd()))\n\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"   # useful on multi-GPU systems with multiple users\n\n# Fix manual seeds for reproducibility\nimport torch\nseed = 42\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\nnp.random.seed(seed)",
  "history_output" : "",
  "history_begin_time" : 1670332329553,
  "history_end_time" : 1670332334504,
  "history_notes" : null,
  "history_process" : "slycsi",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "xwd9l0qlycp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412784,
  "history_end_time" : 1670331412784,
  "history_notes" : null,
  "history_process" : "3hm7db",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8pr6lju8xd5",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412839,
  "history_end_time" : 1670331412839,
  "history_notes" : null,
  "history_process" : "98bbcl",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bamxhq9ng6q",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412848,
  "history_end_time" : 1670331412848,
  "history_notes" : null,
  "history_process" : "ljp3lh",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "rm9jtm1vmxn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412851,
  "history_end_time" : 1670331412851,
  "history_notes" : null,
  "history_process" : "w484ne",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "qg2ol8gca21",
  "history_input" : "#Evaluate model on training and validation sets\n#from eddy_import import *\nfrom pytorch_local import *\nfrom trainingModel import *\nfrom tensorboard_logger import *\nfrom IPython.display import display, HTML\nimport torch\nfrom matplotlib.animation import ArtistAnimation\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.eval()\nwith torch.no_grad():\n    fig, ax = plt.subplots(1, 3, figsize=(25, 10))\n    artists = []\n    # loop through all SSH maps and eddy masks in 2019\n    # and run the model to generate predicted eddy masks\n    for n, (ssh_vars, seg_masks, date_indices) in enumerate(val_loader):\n        ssh_vars = ssh_vars.to(device)\n        seg_masks = seg_masks.to(device)\n        # Run the model to generate predictions\n        preds = model(ssh_vars)\n\n        # For each pixel, EddyNet outputs predictions in probabilities, \n        # so choose the channels (0, 1, or 2) with the highest prob. \n        preds = preds.argmax(dim=1)\n        \n        # Loop through all SSH maps, eddy masks, and predicted masks\n        # in this minibatch and generate a video\n        preds = preds.cpu().numpy()\n        seg_masks = seg_masks.cpu().numpy()\n        ssh_vars = ssh_vars.cpu().numpy()\n        date_indices = date_indices.cpu().numpy()\n        for i in range(len(ssh_vars)):\n            date, img, mask, pred = date_indices[i], ssh_vars[i], seg_masks[i], preds[i]\n            img1, title1, img2, title2, img3, title3 = plot_eddies_on_axes(\n                date, img, mask, pred, ax[0], ax[1], ax[2]\n            )\n            artists.append([img1, title1, img2, title2, img3, title3])\n            fig.canvas.draw()\n            fig.canvas.flush_events()\n    animation = ArtistAnimation(fig, artists, interval=200, blit=True)\n    plt.close()\n    \nanimation.save(os.path.join(tensorboard_dir, \"val_predictions.gif\"), writer=\"pillow\")\nHTML(animation.to_jshtml())\n\nplt.savefig(f'{figOutputFolder}/Animations.png', bbox_inches =\"tight\")",
  "history_output" : "/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n",
  "history_begin_time" : 1670332348315,
  "history_end_time" : 1670332352377,
  "history_notes" : null,
  "history_process" : "ohe0x9",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "i7q862dwz4b",
  "history_input" : "#Demonstrate the beginnings of how one can use classical computer vision techniques to recover eddy contours from the predicted segnmentation masks.\n\n#from eddy_import import *\nfrom animation import *\n\ndef mainFunction():\n  print(\"starting to import\")\n  print('importing done')\n  p = preds[0].astype(np.uint8)\n\n  print(f\"Number of anticyclonic eddies: {count_eddies(p, eddy_type='anticyclonic')}\")\n  print(f\"Number of cyclonic eddies: {count_eddies(p, eddy_type='cyclonic')}\")\n  print(f\"Number of both eddies: {count_eddies(p, eddy_type='both')}\")\n\n  # draw contours on the image\n  thr = cv2.threshold(p, 0, 1, cv2.THRESH_BINARY)[1].astype(np.uint8)\n  contours, hierarchy = cv2.findContours(thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n  img = np.zeros(p.shape, np.uint8)\n  cv2.drawContours(img, contours, -1, (255, 255, 255), 1)\n  plt.imshow(img, cmap=\"gray\")\n  plt.axis(\"off\")\n\n  # get average contour area\n  area = 0\n  for cnt in contours:\n      area += cv2.contourArea(cnt)\n  area /= len(contours)\n  print(f\"Average contour area: {area:.2f} sq. pixels\")\n      \n  plt.savefig(f'{figOutputFolder}/EddyContours.png', bbox_inches =\"tight\")\n  \nif __name__ == \"__main__\":\n  mainFunction()\n",
  "history_output" : "/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n",
  "history_begin_time" : 1670332353795,
  "history_end_time" : 1670332357825,
  "history_notes" : null,
  "history_process" : "kaedp2",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xkk9oiawt62",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412874,
  "history_end_time" : 1670331412874,
  "history_notes" : null,
  "history_process" : "6gs3ym",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "yoacoxw80wc",
  "history_input" : "# Defining the start_axes, update_axes, plot_variabe  and setting the paths for eddy workflow\nfrom eddy_import import *\n\ndef start_axes(title):\n    fig = plt.figure(figsize=(13, 5))\n    ax = fig.add_axes([0.03, 0.03, 0.90, 0.94])\n    ax.set_aspect(\"equal\")\n    ax.set_title(title, weight=\"bold\")\n    return ax\n\n\ndef update_axes(ax, mappable=None):\n    ax.grid()\n    if mappable:\n        plt.colorbar(mappable, cax=ax.figure.add_axes([0.94, 0.05, 0.01, 0.9]))\n\n\ndef plot_variable(grid_object, var_name, ax_title, **kwargs):\n    ax = start_axes(ax_title)\n    m = grid_object.display(ax, var_name, **kwargs)\n    update_axes(ax, m)\n    ax.set_xlim(grid_object.x_c.min(), grid_object.x_c.max())\n    ax.set_ylim(grid_object.y_c.min(), grid_object.y_c.max())\n    return ax, m\n\ndata_root = os.path.join(os.path.expanduser(\"~\"), \"ML_eddies\")\ntrain_folder = os.path.join(data_root, \"cds_ssh_1998-2018_10day_interval\")\ntest_folder = os.path.join(data_root, \"cds_ssh_2019_10day_interval\")\n\nexample_file = os.path.join(test_folder, \"dt_global_twosat_phy_l4_20190101_vDT2021.nc\")\ndate = datetime(2019, 1, 1)\ng = RegularGridDataset(example_file, \"longitude\", \"latitude\")\n\nfigOutputFolder = '/Users/lakshmichetana/ML_Eddies_New_Data_Output/'\n",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\n",
  "history_begin_time" : 1670331413660,
  "history_end_time" : 1670331420453,
  "history_notes" : null,
  "history_process" : "23nut7",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "n4xlp2cqil5",
  "history_input" : "# setting the vmin and vmax using the eddy 'plot_variable' method\n#from eddy_paths import *\nfrom eddy_paths import figOutputFolder, plot_variable, g\nfrom copy import deepcopy\nfrom matplotlib import pyplot as plt\n\n#updated the vmin and vmax to -1 and 1\nax, m = plot_variable(\n    g,\n    \"adt\",\n    f\"ADT (m) before high-pass filter\",\n    vmin=-1,\n    vmax=1,\n)\nplt.savefig(f'{figOutputFolder}/ADT(m)_before_high-pass_filter.png', bbox_inches =\"tight\")\n#updated wavelength covered kilometers to 500 from 700\nwavelength_km = 500\n\ng_filtered = deepcopy(g)\n\ng_filtered.bessel_high_filter(\"adt\", wavelength_km)\nax, m = plot_variable(\n    g_filtered,\n    \"adt\",\n    f\"ADT (m) filtered (Final: {wavelength_km} km)\",\n    vmin=-1,\n    vmax=1,\n)\n\nplt.savefig(f'{figOutputFolder}/ADT(m)-filtered.png', bbox_inches =\"tight\")\n",
  "history_output" : "",
  "history_begin_time" : 1670331421505,
  "history_end_time" : 1670331422405,
  "history_notes" : null,
  "history_process" : "zr8vzj",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pp0g4r8d5tn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412887,
  "history_end_time" : 1670331412887,
  "history_notes" : null,
  "history_process" : "4bd5xp",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "226wdjz2dfp",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412891,
  "history_end_time" : 1670331412891,
  "history_notes" : null,
  "history_process" : "l9f2t3",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "kxuibogvvqt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412899,
  "history_end_time" : 1670331412899,
  "history_notes" : null,
  "history_process" : "4o6voy",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "e4o41xbfder",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412904,
  "history_end_time" : 1670331412904,
  "history_notes" : null,
  "history_process" : "j4jm66",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "8u1roubrbu0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412907,
  "history_end_time" : 1670331412907,
  "history_notes" : null,
  "history_process" : "39ur7y",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "drpp9kjsm4l",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412911,
  "history_end_time" : 1670331412911,
  "history_notes" : null,
  "history_process" : "uolls4",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "gz8vcq6x9mn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412912,
  "history_end_time" : 1670331412912,
  "history_notes" : null,
  "history_process" : "oc42ub",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "43x48h0devc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412914,
  "history_end_time" : 1670331412914,
  "history_notes" : null,
  "history_process" : "bzgeyy",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "ndn20dkg8c1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1670331412916,
  "history_end_time" : 1670331412916,
  "history_notes" : null,
  "history_process" : "bomi2j",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "47mltlniwkj",
  "history_input" : "#getting the test dates and files of training sets from 1998 - 2018 and from training set 2019 and also setting the logging level as ERROR\nfrom eddy_import import *\nfrom importing_multiprocessor import *\nfrom eddy_paths import *\nfrom eddy_plots import *\nimport logging\nfrom subset_arrays import *\n#from Generate_Masks import *\n# northern pacific (32x32 degree -> 128x128 pixels)\n\ndef funcGenerateMasks():\n  logging.getLogger(\"pet\").setLevel(logging.ERROR)\n\n    # enter the AVISO filename pattern\n    # year, month, and day in file_pattern will be filled in get_dates_and_files:\n  file_pattern = \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n  # training set: 1998 - 2018\n  train_dates, train_files = get_dates_and_files(\n      range(1998, 2019), range(1, 13), [1, 10, 20, 30], train_folder, file_pattern\n  )\n  train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n      train_files, train_dates\n  )\n\n\n# test set: 2019\n  test_dates, test_files = get_dates_and_files(\n      [2019], range(1, 13), [1, 10, 20, 30], test_folder, file_pattern\n  )\n  test_adt, test_adt_filtered, test_masks = generate_masks_in_parallel(\n      test_files, test_dates\n  )\n\n\n  lon_range = (-166, -134)\n  lat_range = (14, 46)\n\n  train_subset = subset_arrays(\n      train_masks,\n      train_adt,\n      train_adt_filtered,\n      train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n  )\n\n  test_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n  )\n\n  plt.savefig(f'{figOutputFolder}/Train_Test_Subset_Img.png', bbox_inches =\"tight\")\n\nif __name__ == \"__main__\":\n  funcGenerateMasks()\n",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nFound 987 files for 1998-2018.\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19980101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19980420_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19980730_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19981101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19990210_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19990530_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19990901_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19991210_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20000330_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20000701_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20001010_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20010120_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20010501_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20010810_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20011120_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20020301_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20020610_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20020920_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20021230_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20030410_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20030720_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20031030_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040201_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040520_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040830_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20041201_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20050320_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20050630_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20051001_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20060110_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20060430_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20060801_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20061110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20070220_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20070601_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20070910_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20071220_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20080401_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20080710_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20081020_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20090130_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20090510_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20090820_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20091130_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20100310_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20100620_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20100930_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20110101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20110420_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20110730_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20111101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20120210_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20120530_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20120901_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20121210_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20130330_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20130701_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20131010_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20140120_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20140501_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20140810_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20141120_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20150301_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20150610_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20150920_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20151230_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20160410_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20160720_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20161030_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20170201_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20170520_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20170830_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20171201_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20180320_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20180630_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20181001_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo extrema found in contour of 4 pixels in level -0.030000\nNo extrema found in contour of 6 pixels in level 0.010000\nNo extrema found in contour of 4 pixels in level -0.020000\nNo extrema found in contour of 4 pixels in level -0.025000\nNo extrema found in contour of 4 pixels in level -0.035000\nNo extrema found in contour of 4 pixels in level -0.050000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20061120_vDT2021.nc\nNo extrema found in contour of 4 pixels in level -0.090000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20001020_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20060810_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20031101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20020310_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19980430_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19980110_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20070610_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19990601_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040210_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19990220_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20070301_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040530_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19981110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20010510_vDT2021.nc\nNo extrema found in contour of 4 pixels in level 0.030000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20031110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo extrema found in contour of 4 pixels in level -0.060000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19980501_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040601_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19981120_vDT2021.nc\nNo extrema found in contour of 5 pixels in level 0.015000\nNo extrema found in contour of 4 pixels in level -0.010000\nNo extrema found in contour of 4 pixels in level -0.030000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20031120_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo extrema found in contour of 4 pixels in level -0.065000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19980510_vDT2021.nc\nNo extrema found in contour of 4 pixels in level -0.125000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040610_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo extrema found in contour of 4 pixels in level 0.070000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20031130_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040620_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20031201_vDT2021.nc\nNo extrema found in contour of 4 pixels in level 0.090000\nNo extrema found in contour of 4 pixels in level -0.015000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040630_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nNo extrema found in contour of 4 pixels in level 0.255000\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_20040701_vDT2021.nc\nmultiprocessing.pool.RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"/Users/lakshmichetana/gw-workspace/47mltlniwkj/eddy_plots.py\", line 19, in generate_segmentation_mask_from_file\n    g, g_filtered, anticyclonic, cyclonic = identify_eddies(\n  File \"/Users/lakshmichetana/gw-workspace/47mltlniwkj/eddy_plots.py\", line 38, in identify_eddies\n    g = RegularGridDataset(gridded_ssh_file, \"longitude\", \"latitude\")\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/site-packages/py_eddy_tracker/dataset/grid.py\", line 1186, in __init__\n    super().__init__(*args, **kwargs)\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/site-packages/py_eddy_tracker/dataset/grid.py\", line 310, in __init__\n    self.load_general_features()\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/site-packages/py_eddy_tracker/dataset/grid.py\", line 331, in load_general_features\n    with Dataset(self.filename) as h:\n  File \"src/netCDF4/_netCDF4.pyx\", line 2463, in netCDF4._netCDF4.Dataset.__init__\n  File \"src/netCDF4/_netCDF4.pyx\", line 2026, in netCDF4._netCDF4._ensure_nc_success\nFileNotFoundError: [Errno 2] No such file or directory: b'/Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19980730_vDT2021.nc'\n\"\"\"\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/Users/lakshmichetana/gw-workspace/47mltlniwkj/generateMasks_TrainTestPlots.py\", line 66, in <module>\n    funcGenerateMasks()\n  File \"/Users/lakshmichetana/gw-workspace/47mltlniwkj/generateMasks_TrainTestPlots.py\", line 22, in funcGenerateMasks\n    train_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n  File \"/Users/lakshmichetana/gw-workspace/47mltlniwkj/importing_multiprocessor.py\", line 26, in generate_masks_in_parallel\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 372, in starmap\n    return self._map_async(func, iterable, starmapstar, chunksize).get()\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 771, in get\n    raise self._value\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"/Users/lakshmichetana/gw-workspace/47mltlniwkj/eddy_plots.py\", line 19, in generate_segmentation_mask_from_file\n    g, g_filtered, anticyclonic, cyclonic = identify_eddies(\n  File \"/Users/lakshmichetana/gw-workspace/47mltlniwkj/eddy_plots.py\", line 38, in identify_eddies\n    g = RegularGridDataset(gridded_ssh_file, \"longitude\", \"latitude\")\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/site-packages/py_eddy_tracker/dataset/grid.py\", line 1186, in __init__\n    super().__init__(*args, **kwargs)\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/site-packages/py_eddy_tracker/dataset/grid.py\", line 310, in __init__\n    self.load_general_features()\n  File \"/Users/lakshmichetana/opt/anaconda3/lib/python3.9/site-packages/py_eddy_tracker/dataset/grid.py\", line 331, in load_general_features\n    with Dataset(self.filename) as h:\n  File \"src/netCDF4/_netCDF4.pyx\", line 2463, in netCDF4._netCDF4.Dataset.__init__\n  File \"src/netCDF4/_netCDF4.pyx\", line 2026, in netCDF4._netCDF4._ensure_nc_success\nFileNotFoundError: [Errno 2] No such file or directory: b'/Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/dt_global_twosat_phy_l4_19980730_vDT2021.nc'\n/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 20 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n",
  "history_begin_time" : 1670331465372,
  "history_end_time" : 1670332327658,
  "history_notes" : null,
  "history_process" : "uji5d1",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "mc7q4umlui4",
  "history_input" : "from file_paths import *\nfrom declaring_epochs_size import *\nfrom data_utils import get_eddy_dataloader\nfrom eddy_import import *\nimport numpy as np\nimport torch\nfrom get_eddy_dataloader import *\nfrom eddynet import EddyNet\nfrom eddy_paths import figOutputFolder\n\n# set binary = false if we want to distinguish between cyclonic and anticyclonic\nbinary = False\nnum_classes = 2 if binary else 3\ntrain_loader, _ = get_eddy_dataloader(train_file, binary=binary, batch_size=batch_size)\nval_loader, _ = get_eddy_dataloader(\n    val_file, binary=binary, batch_size=batch_size, shuffle=False\n)\n\n#Looking at the distribution of class frequencies to identify class imbalances\ntrain_masks = train_loader.dataset.masks.copy()\nclass_frequency = np.bincount(train_masks.flatten())\ntotal_pixels = sum(class_frequency)\nprint(\n    f\"Total number of pixels in training set: {total_pixels/1e6:.2f} megapixels\"\n    f\" across {len(train_masks)} SSH maps\\n\"\n    f\"Number of pixels that are not eddies: {class_frequency[0]/1e6:.2f} megapixels \"\n    f\"({class_frequency[0]/total_pixels * 100:.2f}%)\\n\"\n    f\"Number of pixels that are anticyclonic eddies: {class_frequency[1]/1e6:.2f} megapixels \"\n    f\"({class_frequency[1]/total_pixels * 100:.2f}%)\\n\"\n    f\"Number of pixels that are cyclonic eddies: {class_frequency[2]/1e6:.2f} megapixels \"\n    f\"({class_frequency[2]/total_pixels * 100:.2f}%)\\n\"\n)\n\n#Using plot_sample to visualize the dataset we just loaded.\ntrain_loader.dataset.plot_sample(N=3)\nplt.savefig(f\"{figOutputFolder}/datasetPlots\",bbox=\"tight\")\n\n#Segmentation Model:\nnum_classes = 2 if binary else 3\nmodel_name = \"eddynet\"  # we'll log this in Tensorboard\nmodel = EddyNet(num_classes, num_filters=16, kernel_size=3)\nif torch.cuda.is_available(): \n    model.to(device=\"cuda\")",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\n/Users/lakshmichetana/gw-workspace/mc7q4umlui4/EddyDataLoader_PixelTraining_TrainingDataset_&_Pytorch.py:36: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"bbox\" which is no longer supported as of 3.3 and will become an error in 3.6\n  plt.savefig(f\"{figOutputFolder}/datasetPlots\",bbox=\"tight\")\nRead 987 samples from /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 47 samples from /Users/lakshmichetana/ML_eddies/dataset-satellite-sea-level-global-601bf215-53f9-47ac-bb7f-690c0c65c7c3/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\nRead 987 samples from /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 47 samples from /Users/lakshmichetana/ML_eddies/dataset-satellite-sea-level-global-601bf215-53f9-47ac-bb7f-690c0c65c7c3/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\nTotal number of pixels in training set: 16.17 megapixels across 987 SSH maps\nNumber of pixels that are not eddies: 11.71 megapixels (72.43%)\nNumber of pixels that are anticyclonic eddies: 2.33 megapixels (14.39%)\nNumber of pixels that are cyclonic eddies: 2.13 megapixels (13.18%)\n",
  "history_begin_time" : 1670332335809,
  "history_end_time" : 1670332341234,
  "history_notes" : null,
  "history_process" : "qsxf3a",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "hdxoislev0f",
  "history_input" : "#loss function\nprint('start imports')\n#import torch\nprint('torch')\n#from eddy_import import *\nprint('eddy_import')\nfrom pytorch_local import *\nprint('pytorch_local')\nfrom data_utils import *\nprint('get_eddy_dataloader')\nimport torchmetrics\nprint('torchmetrics')\nimport datetime\nprint('datetime')\nfrom torch.utils.tensorboard import SummaryWriter\nprint('SummaryWriter')\nimport cv2  # use cv2 to count eddies by drawing contours around segmentation masks\nprint('cv2')\nimport matplotlib.pyplot as plt\nprint('matplotlib.pyplot')\n#import numpy as np\n\nfrom tqdm.auto import tqdm\nprint('tqdm.auto ')\nfrom eddy_train_utils import run_batch, write_metrics_to_tensorboard, filter_scalar_metrics, EarlyStopping\nprint('end of imports')\n\n#Run the training loop for prescribed num_epochs\nfrom declaring_epochs_size import *\nfrom eddy_train_utils import add_hparams\n\nprint('Before Loss Function')\nloss_fn = torch.nn.CrossEntropyLoss()\nprint('After loss Function')\n# TODO (homework): Try \n# loss_fn = torch.nn.CrossEntropyLoss(weight=torch.Tensor(total_pixels/class_frequency))\n\n# learning rate for use in OneCycle scheduler\ninitial_lr = 1e-6\nmax_lr = 5e-4\n\nprint('Before scheduler initiation')\noptimizer = torch.optim.Adam(model.parameters(), lr=max_lr)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=max_lr,\n    steps_per_epoch=len(train_loader),\n    epochs=num_epochs,\n    div_factor=max_lr / initial_lr,\n    pct_start=0.3,\n)\nprint('after scheduler initiation')\n\n#Defining and using the get_metrics function\ndef get_metrics(N, sync=False):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n#         torchmetrics.F1Score(  # TODO: Homework: verify in tensorboard that this is equivalent to accuracy\n#             average=\"micro\",\n#             dist_sync_on_step=sync,\n#             num_classes=N,\n#         ),\n        torchmetrics.F1Score(\n            average=\"none\",  # return F1 for each class\n            dist_sync_on_step=sync,\n            num_classes=N,\n        )\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\ntrain_metrics, val_metrics = get_metrics(num_classes)\n\n\n#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nimport datetime\nprint('before tensorboard dir')\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)\nprint('after tensorboard dir')\n\n#Train the model: Defining training loop\n\nnum_plots_in_tensorboard = 5\n# will populate this later with random numbers:\nrandom_plot_indices = np.zeros((num_plots_in_tensorboard,), np.uint8)\n\nprint('before run_epoch')\ndef run_epoch(\n    epoch,\n    model,\n    loss_fn,\n    optimizer,\n    scheduler,\n    train_loader,\n    val_loader,\n    train_metrics,\n    val_metrics,\n    writer,\n):\n    leave = epoch == num_epochs - 1  # leave progress bar on screen after last epoch\n\n    model.train()\n    # training set\n    for batch_num, (gvs, seg_masks, date_indices) in enumerate(train_loader):\n        train_loss = run_batch(\n            model, loss_fn, gvs, seg_masks, optimizer, scheduler, train_metrics\n        )\n        iter_num = epoch * len(train_loader) + batch_num\n        writer.add_scalar(\"train/lr\", scheduler.get_last_lr()[-1], iter_num)\n\n    # validation set\n    images, preds, labels, dates = [], [], [], []\n    model.eval()\n    with torch.no_grad():\n        val_loss = num_examples = 0\n        for gvs, masks, date_indices in val_loader:\n            # continue\n            loss_, pred_batch = run_batch(\n                model, loss_fn, gvs, masks, metrics=val_metrics, return_pred=True\n            )\n            val_loss += loss_\n            num_examples += np.prod(gvs.shape)\n            # keep track of images, preds, labels for plotting\n            images.append(gvs)\n            preds.append(pred_batch)\n            labels.append(masks)\n            dates.append(date_indices)\n\n    # calculate average validation loss across all samples\n    # num_examples should be equal to sum of all pixels\n    val_loss = val_loss / num_examples\n\n    # plot validation images and log to tensorboard\n    ## move images, preds, labels, dates to cpu\n    images = torch.cat(images).cpu().numpy()\n    labels = torch.cat(labels).cpu().numpy()\n    preds = torch.cat(preds).cpu().numpy()\n    dates = torch.cat(dates).cpu().numpy()\n    ## convert indices to actual dates\n    dates = [val_loader.dataset.dates[i].strftime(\"%Y-%m-%d\") for i in dates]\n\n    # take random images from validation set\n    if epoch == 0:\n        indices_ = np.random.choice(\n            len(images), num_plots_in_tensorboard, replace=False\n        )\n        for i, idx in enumerate(indices_):\n            random_plot_indices[i] = idx\n    fig, ax = plt.subplots(num_plots_in_tensorboard, 3, figsize=(20, 30))\n    for n, i in enumerate(random_plot_indices):\n        date, img, mask, pred = dates[i], images[i], labels[i], preds[i]\n        artists = plot_eddies_on_axes(\n            date, img, mask, pred, ax[n, 0], ax[n, 1], ax[n, 2]\n        )\n    plt.tight_layout()\n    writer.add_figure(f\"val/sample_prediction\", fig, global_step=epoch)\n\n    # Update tensorboard\n    train_m = write_metrics_to_tensorboard(\n        num_classes, train_metrics, writer, epoch, \"train\"\n    )\n    val_m = write_metrics_to_tensorboard(num_classes, val_metrics, writer, epoch, \"val\")\n\n    writer.add_scalar(\"train/loss\", train_loss, epoch)\n    writer.add_scalar(\"val/loss\", val_loss, epoch)\n\n    # reset metrics after each epoch\n    train_metrics.reset()\n    val_metrics.reset()\n\n    train_m = filter_scalar_metrics(train_m)\n    val_m = filter_scalar_metrics(val_m)\n\n    return train_loss, val_loss, train_m, val_m\nprint('after run_epoch')\n\ndef plot_eddies_on_axes(date, img, mask, pred, a1, a2, a3):\n    im1 = a1.imshow(img.squeeze(), cmap=\"viridis\")\n\n    # blit canvas for a1 a2 a3\n    a1.figure.canvas.draw()\n    a1.figure.canvas.flush_events()\n    a2.figure.canvas.draw()\n    a2.figure.canvas.flush_events()\n    a3.figure.canvas.draw()\n    a3.figure.canvas.flush_events()\n\n    # https://stackoverflow.com/a/49159236\n    t1 = a1.text(\n        0.5,\n        1.05,\n        f\"ADT {date}\",\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a1.transAxes,\n    )\n    # set axis off\n    a1.axis(\"off\")\n\n    # count number of eddies in mask and pred\n    mask_anticyclonic = count_eddies(mask, \"anticyclonic\")\n    mask_cyclonic = count_eddies(mask, \"cyclonic\")\n    pred_anticyclonic = count_eddies(pred, \"anticyclonic\")\n    pred_cyclonic = count_eddies(pred, \"cyclonic\")\n\n    # calculate accuracy between pred and mask\n    acc = np.sum(pred == mask) / mask.size\n    im2 = a2.imshow(pred, cmap=\"viridis\")\n    t2 = a2.text(\n        0.5,\n        1.05,\n        (\n            f\"Prediction (Acc = {acc:.3f} |\"\n            f\" Num. anticyclonic = {pred_anticyclonic} |\"\n            f\" Num. cyclonic = {pred_cyclonic})\"\n        ),\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a2.transAxes,\n    )\n    a2.axis(\"off\")\n    im3 = a3.imshow(mask, cmap=\"viridis\")\n    t3 = a3.text(\n        0.5,\n        1.05,\n        (\n            f\"Ground Truth\"\n            f\" (Num. anticyclonic: {mask_anticyclonic} |\"\n            f\" Num. cyclonic: {mask_cyclonic})\"\n        ),\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a3.transAxes,\n    )\n    a3.axis(\"off\")\n\n    return im1, t1, im2, t2, im3, t3\n\n\ndef count_eddies(arr, eddy_type=\"both\"):\n    mask = np.zeros(arr.shape, dtype=np.uint8)\n    if eddy_type == \"anticyclonic\":\n        mask[arr == 1] = 1\n    elif eddy_type == \"cyclonic\":\n        mask[arr == 2] = 1\n    else:\n        mask[arr > 0] = 1\n    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    return len(contours)\n\n# create some aliases\nloss, opt, sched = loss_fn, optimizer, scheduler\nnum_epochs = 5\n\ncheckpoint_path = os.path.join(tensorboard_dir, \"model_ckpt_{epoch}.pt\")\nearly_stopping = EarlyStopping(\n    patience=10,\n    path=checkpoint_path,\n    min_epochs=30,\n)\n\nprogress_bar = tqdm(range(num_epochs), desc=\"Training: \", unit=\"epoch(s)\")\nfor N in progress_bar:\n    train_loss, val_loss, train_m, val_m = run_epoch(\n        N,\n        model,\n        loss,\n        opt,\n        sched,\n        train_loader,\n        val_loader,\n        train_metrics,\n        val_metrics,\n        writer,\n    )\n\n    # update progress bar\n    train_m_copy = {f\"train_{k}\".lower(): v.cpu().numpy() for k, v in train_m.items()}\n    val_m_copy = {f\"val_{k}\".lower(): v.cpu().numpy() for k, v in val_m.items()}\n    progress_bar.set_postfix(**train_m_copy, **val_m_copy)\n\n    # early stopping when validation loss stops improving\n    early_stopping.path = checkpoint_path.format(epoch=N)\n    early_stopping(val_loss, model)\n    if early_stopping.early_stop:\n        print(\n            f\"Early stopping at epoch {N}\"\n            f\" with validation loss {val_loss:.3f}\"\n            f\" and training loss {train_loss:.3f}\"\n        )\n        break\n\n    # TODO (homework): save checkpoint every 10 epochs\n\n# add hyperparameters and corresponding results to tensorboard HParams table\nhparam_dict = {\n    \"backbone\": model_name,\n    \"num_epochs\": num_epochs,\n    \"batch_size\": batch_size,\n    \"num_classes\": num_classes,\n    \"binary_mask\": binary,\n    \"optimizer\": optimizer.__class__.__name__,\n    \"max_lr\": max_lr,\n    \"loss_function\": loss_fn.__class__.__name__,\n}\nmetrics_dict = {\n    \"train/end_epoch\": N,\n    \"train/loss\": train_loss,\n    \"train/Accuracy\": train_m[\"Accuracy\"],\n    \"val/loss\": val_loss,\n    \"val/Accuracy\": val_m[\"Accuracy\"],\n}\nadd_hparams(writer, hparam_dict, metrics_dict, epoch_num=N)\nwriter.close()\n\nprint('model path setting')\n# save model to tensorboard folder\nmodel_path = os.path.join(tensorboard_dir, f\"model_ckpt_{N+1}.pt\")\nprint('entering save option')\ntorch.save(model.state_dict(), model_path)",
  "history_output" : "/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n",
  "history_begin_time" : 1670332342550,
  "history_end_time" : 1670332346743,
  "history_notes" : null,
  "history_process" : "tldnzh",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "fvwyyt7nqrb",
  "history_input" : "# setting the vmin and vmax using the eddy 'plot_variable' method\nfrom eddy_paths import *\nfrom copy import deepcopy\nfrom matplotlib import pyplot as plt\n\n#updated the vmin and vmax to -1 and 1\nax, m = plot_variable(\n    g,\n    \"adt\",\n    f\"ADT (m) before high-pass filter\",\n    vmin=-5,\n    vmax=5,\n)\nplt.savefig(f'{figOutputFolder}/ADT(m)_before_high-pass_filter_with_updatedVminVmax&Wavelength_KM.png', bbox_inches =\"tight\")\n#updated wavelength covered kilometers to 100 from 700\nwavelength_km = 100\n\ng_filtered = deepcopy(g)\n\ng_filtered.bessel_high_filter(\"adt\", wavelength_km)\nax, m = plot_variable(\n    g_filtered,\n    \"adt\",\n    f\"ADT (m) filtered (Final: {wavelength_km} km)\",\n    vmin=-5,\n    vmax=5,\n)\n\nplt.savefig(f'{figOutputFolder}/ADT(m)-filtered_with_updatedVminVmax&Wavelength_KM.png', bbox_inches =\"tight\")\n",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n",
  "history_begin_time" : 1670331422509,
  "history_end_time" : 1670331428195,
  "history_notes" : null,
  "history_process" : "k3gm1y",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "jyssydxqiu4",
  "history_input" : "#code for plotting segmentation masks, antcyclonic display, cyclonic display and updating the axis\nfrom eddy_plots import *\nfrom eddy_paths import *\nfrom copy import deepcopy\n\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-0.15, vmax=0.15, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-180\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-180\n)\nax.legend()\nupdate_axes(ax)\n\nplt.savefig('/Users/lakshmichetana/ML_eddies_Output/Detected Eddies on ADT (m).png', bbox_inches =\"tight\")\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)\nplt.savefig('/Users/lakshmichetana/ML_eddies_Output/Segmentation Mask.png', bbox_inches =\"tight\")",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n",
  "history_begin_time" : 1670331423428,
  "history_end_time" : 1670331464242,
  "history_notes" : null,
  "history_process" : "2if9sm",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ry7mhdbnerw",
  "history_input" : "#code for plotting segmentation masks, antcyclonic display, cyclonic display and updating the axis\nfrom eddy_plots import *\nfrom eddy_paths import *\nfrom copy import deepcopy\n\n#updated the r4ef details and also the vmin and vmax values\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-5, vmax=5, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-250\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-250\n)\nax.legend()\nupdate_axes(ax)\n\nplt.savefig('/Users/lakshmichetana/ML_eddies_Output/Detected Eddies on ADT (m)_with_UpdatedVminVmax&RefValues.png', bbox_inches =\"tight\")\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)\nplt.savefig(f'{figOutputFolder}/Segmentation Mask_with_UpdatedVminVmax&RefValues.png', bbox_inches =\"tight\")",
  "history_output" : "We assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nWe assume pixel position of grid is centered for /Users/lakshmichetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190101_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n",
  "history_begin_time" : 1670331465755,
  "history_end_time" : 1670332033142,
  "history_notes" : null,
  "history_process" : "xm5gfq",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3qd3pzp0d55",
  "history_input" : "#Segmentation Model:\n\nfrom eddy_import import *\nfrom Eddy_Dataloader import *\nimport torch\n#from models.eddynet import EddyNet\nfrom eddynet import EddyNet\nnum_classes = 2 if binary else 3\nmodel_name = \"eddynet\"  # we'll log this in Tensorboard\nmodel = EddyNet(num_classes, num_filters=16, kernel_size=3)\nif torch.cuda.is_available(): \n    model.to(device=\"cuda\")",
  "history_output" : "Read 987 samples from /Users/lakshmichetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 47 samples from /Users/lakshmichetana/ML_eddies/dataset-satellite-sea-level-global-601bf215-53f9-47ac-bb7f-690c0c65c7c3/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\n",
  "history_begin_time" : 1670331413680,
  "history_end_time" : 1670331422553,
  "history_notes" : null,
  "history_process" : "399tue",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ont0dfywf5j",
  "history_input" : "from file_paths import *\nfrom declaring_epochs_size import *\nfrom data_utils import get_eddy_dataloader\n\n# set binary = false if we want to distinguish between cyclonic and anticyclonic\nbinary = False\nnum_classes = 2 if binary else 3\ntrain_loader, _ = get_eddy_dataloader(train_file, binary=binary, batch_size=batch_size)\nval_loader, _ = get_eddy_dataloader(\n    val_file, binary=binary, batch_size=batch_size, shuffle=False\n)",
  "history_output" : "",
  "history_begin_time" : 1670331413683,
  "history_end_time" : 1670331420485,
  "history_notes" : null,
  "history_process" : "o8ujvl",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "knmqsgwl039",
  "history_input" : "#Train the model: Defining training loop\n\nfrom eddy_import import *\nimport cv2  # use cv2 to count eddies by drawing contours around segmentation masks\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom eddy_train_utils import run_batch, write_metrics_to_tensorboard, filter_scalar_metrics, EarlyStopping\n\nnum_plots_in_tensorboard = 5\n# will populate this later with random numbers:\nrandom_plot_indices = np.zeros((num_plots_in_tensorboard,), np.uint8)\n\n\ndef run_epoch(\n    epoch,\n    model,\n    loss_fn,\n    optimizer,\n    scheduler,\n    train_loader,\n    val_loader,\n    train_metrics,\n    val_metrics,\n    writer,\n):\n    leave = epoch == num_epochs - 1  # leave progress bar on screen after last epoch\n\n    model.train()\n    # training set\n    for batch_num, (gvs, seg_masks, date_indices) in enumerate(train_loader):\n        train_loss = run_batch(\n            model, loss_fn, gvs, seg_masks, optimizer, scheduler, train_metrics\n        )\n        iter_num = epoch * len(train_loader) + batch_num\n        writer.add_scalar(\"train/lr\", scheduler.get_last_lr()[-1], iter_num)\n\n    # validation set\n    images, preds, labels, dates = [], [], [], []\n    model.eval()\n    with torch.no_grad():\n        val_loss = num_examples = 0\n        for gvs, masks, date_indices in val_loader:\n            # continue\n            loss_, pred_batch = run_batch(\n                model, loss_fn, gvs, masks, metrics=val_metrics, return_pred=True\n            )\n            val_loss += loss_\n            num_examples += np.prod(gvs.shape)\n            # keep track of images, preds, labels for plotting\n            images.append(gvs)\n            preds.append(pred_batch)\n            labels.append(masks)\n            dates.append(date_indices)\n\n    # calculate average validation loss across all samples\n    # num_examples should be equal to sum of all pixels\n    val_loss = val_loss / num_examples\n\n    # plot validation images and log to tensorboard\n    ## move images, preds, labels, dates to cpu\n    images = torch.cat(images).cpu().numpy()\n    labels = torch.cat(labels).cpu().numpy()\n    preds = torch.cat(preds).cpu().numpy()\n    dates = torch.cat(dates).cpu().numpy()\n    ## convert indices to actual dates\n    dates = [val_loader.dataset.dates[i].strftime(\"%Y-%m-%d\") for i in dates]\n\n    # take random images from validation set\n    if epoch == 0:\n        indices_ = np.random.choice(\n            len(images), num_plots_in_tensorboard, replace=False\n        )\n        for i, idx in enumerate(indices_):\n            random_plot_indices[i] = idx\n    fig, ax = plt.subplots(num_plots_in_tensorboard, 3, figsize=(20, 30))\n    for n, i in enumerate(random_plot_indices):\n        date, img, mask, pred = dates[i], images[i], labels[i], preds[i]\n        artists = plot_eddies_on_axes(\n            date, img, mask, pred, ax[n, 0], ax[n, 1], ax[n, 2]\n        )\n    plt.tight_layout()\n    writer.add_figure(f\"val/sample_prediction\", fig, global_step=epoch)\n\n    # Update tensorboard\n    train_m = write_metrics_to_tensorboard(\n        num_classes, train_metrics, writer, epoch, \"train\"\n    )\n    val_m = write_metrics_to_tensorboard(num_classes, val_metrics, writer, epoch, \"val\")\n\n    writer.add_scalar(\"train/loss\", train_loss, epoch)\n    writer.add_scalar(\"val/loss\", val_loss, epoch)\n\n    # reset metrics after each epoch\n    train_metrics.reset()\n    val_metrics.reset()\n\n    train_m = filter_scalar_metrics(train_m)\n    val_m = filter_scalar_metrics(val_m)\n\n    return train_loss, val_loss, train_m, val_m\n\n\ndef plot_eddies_on_axes(date, img, mask, pred, a1, a2, a3):\n    im1 = a1.imshow(img.squeeze(), cmap=\"viridis\")\n\n    # blit canvas for a1 a2 a3\n    a1.figure.canvas.draw()\n    a1.figure.canvas.flush_events()\n    a2.figure.canvas.draw()\n    a2.figure.canvas.flush_events()\n    a3.figure.canvas.draw()\n    a3.figure.canvas.flush_events()\n\n    # https://stackoverflow.com/a/49159236\n    t1 = a1.text(\n        0.5,\n        1.05,\n        f\"ADT {date}\",\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a1.transAxes,\n    )\n    # set axis off\n    a1.axis(\"off\")\n\n    # count number of eddies in mask and pred\n    mask_anticyclonic = count_eddies(mask, \"anticyclonic\")\n    mask_cyclonic = count_eddies(mask, \"cyclonic\")\n    pred_anticyclonic = count_eddies(pred, \"anticyclonic\")\n    pred_cyclonic = count_eddies(pred, \"cyclonic\")\n\n    # calculate accuracy between pred and mask\n    acc = np.sum(pred == mask) / mask.size\n    im2 = a2.imshow(pred, cmap=\"viridis\")\n    t2 = a2.text(\n        0.5,\n        1.05,\n        (\n            f\"Prediction (Acc = {acc:.3f} |\"\n            f\" Num. anticyclonic = {pred_anticyclonic} |\"\n            f\" Num. cyclonic = {pred_cyclonic})\"\n        ),\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a2.transAxes,\n    )\n    a2.axis(\"off\")\n    im3 = a3.imshow(mask, cmap=\"viridis\")\n    t3 = a3.text(\n        0.5,\n        1.05,\n        (\n            f\"Ground Truth\"\n            f\" (Num. anticyclonic: {mask_anticyclonic} |\"\n            f\" Num. cyclonic: {mask_cyclonic})\"\n        ),\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a3.transAxes,\n    )\n    a3.axis(\"off\")\n\n    return im1, t1, im2, t2, im3, t3\n\n\ndef count_eddies(arr, eddy_type=\"both\"):\n    mask = np.zeros(arr.shape, dtype=np.uint8)\n    if eddy_type == \"anticyclonic\":\n        mask[arr == 1] = 1\n    elif eddy_type == \"cyclonic\":\n        mask[arr == 2] = 1\n    else:\n        mask[arr > 0] = 1\n    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    return len(contours)",
  "history_output" : "",
  "history_begin_time" : 1670331413673,
  "history_end_time" : 1670331422237,
  "history_notes" : null,
  "history_process" : "rk2na1",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "q5j50cv5akc",
  "history_input" : "#Tensor Logger\n#We use the tensor logger to log our loss and metrics throughout the training process.\nfrom eddy_import import *\n\nimport datetime\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)",
  "history_output" : "/Users/lakshmichetana/opt/anaconda3/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n",
  "history_begin_time" : 1670331413686,
  "history_end_time" : 1670331421503,
  "history_notes" : null,
  "history_process" : "lo7r50",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "u1c8hmromht",
  "history_input" : "#Defining the subset arrays, converting the latitude and longitude range into indices in numpy, latitude range to str and longitude range to str.\nfrom eddy_import import *\ndef subset_arrays(\n    masks,\n    var,\n    var_filtered,\n    dates,\n    lon_range,\n    lat_range,\n    resolution_deg,\n    plot=False,\n    ssh_var=\"adt\",\n    save_folder=None,\n):\n    \"\"\"\n    Subset the arrays to the given lon_range and lat_range.\n\n    Args:\n        masks (np.ndarray): Global eddy segmentation masks.\n            Can be masks from multiple dates concatenated into one array\n        var (np.ndarray): Global SSH value\n        var_filtered (np.ndarray): Global SSH value after high-pass filter\n        dates (list): List of `datetime` objects\n        lon_range (tuple): Longitude range to subset to (lon_start, lon_end)\n        lat_range (tuple): Latitude range to subset to (lat_start, lat_end)\n        resolution_deg (float): Resolution of the SSH map in degrees\n        plot (bool): Whether to plot a sample of the subsetted arrays\n        ssh_var (str): SSH variable name. Defaults to \"adt\". Only used if save_folder is not None.\n        save_folder (str): Folder to save the subsetted arrays to. Defaults to None.\n            If None, the arrays are not saved.\n\n    Returns:\n        mask_subset (np.ndarray): Subsetted masks\n        var_subset (np.ndarray): Subsetted var\n        var_filtered_subset (np.ndarray): Subsetted var_filtered\n        lon_subset (np.ndarray): Subsetted lon\n        lat_subset (np.ndarray): Subsetted lat\n    \"\"\"\n    lon_bounds = np.arange(-180, 180 + resolution_deg, resolution_deg) \n    lat_bounds = np.arange(-90, 90 + resolution_deg, resolution_deg)\n\n    # convert lon_range and lat_range to indices in the numpy arrays\n    lon_start, lon_end = lon_range\n    lat_start, lat_end = lat_range\n    lon_idx = lambda lon: np.argmin(np.abs(lon_bounds - lon))\n    lat_idx = lambda lat: np.argmin(np.abs(lat_bounds - lat))\n    lon_start_idx, lon_end_idx = lon_idx(lon_start), lon_idx(lon_end)\n    lat_start_idx, lat_end_idx = lat_idx(lat_start), lat_idx(lat_end)\n\n    mask_subset = masks[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_subset = var[:, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx]\n    var_filtered_subset = var_filtered[\n        :, lon_start_idx:lon_end_idx, lat_start_idx:lat_end_idx\n    ]\n    lon_subset = lon_bounds[lon_start_idx : lon_end_idx + 1]\n    lat_subset = lat_bounds[lat_start_idx : lat_end_idx + 1]\n    if plot:\n        fig, ax = plt.subplots()\n        if mask_subset.ndim == 3:\n            m = mask_subset[0]\n            v = var_subset[0]\n        elif mask_subset.ndim == 2:\n            m = mask_subset\n            v = var_subset\n        ax.pcolormesh(lon_subset, lat_subset, m.T, vmin=0, vmax=2, cmap=\"viridis\")\n        ax.set_xlim(lon_start, lon_end)\n        ax.set_ylim(lat_start, lat_end)\n        ax.set_aspect(abs((lon_end - lon_start) / (lat_start - lat_end)) * 1.0)\n\n    if save_folder is not None:\n        all_years = sorted(set([d.year for d in dates]))\n        year_str = (\n            f\"{all_years[0]}\"\n            if len(all_years) == 1\n            else f\"{min(all_years)}-{max(all_years)}\"\n        )\n        lat_str = lat_range_to_str(lat_range)\n        lon_str = lon_range_to_str(lon_range)\n        save_path = os.path.join(\n            save_folder,\n            f\"subset_pet_masks_with_{ssh_var}_{year_str}_lat{lat_str}_lon{lon_str}.npz\",\n        )\n        np.savez_compressed(\n            save_path,\n            masks=mask_subset,\n            dates=dates,\n            var=var_subset,\n            var_filtered=var_filtered_subset,\n            lon_subset=lon_subset,\n            lat_subset=lat_subset,\n        )\n        print(f\"Saved mask subset to {save_path}\")\n    return mask_subset, var_subset, var_filtered_subset, lon_subset, lat_subset\n\n\ndef lon_range_to_str(lon_range):\n    lon_start, lon_end = lon_range\n    lon_start = f\"{lon_start}E\" if lon_start >= 0 else f\"{abs(lon_start)}W\"\n    lon_end = f\"{lon_end}E\" if lon_end >= 0 else f\"{abs(lon_end)}W\"\n    return f\"{lon_start}-{lon_end}\"\n\ndef lat_range_to_str(lat_range):\n    lat_start, lat_end = lat_range\n    lat_start = f\"{lat_start}N\" if lat_start >= 0 else f\"{abs(lat_start)}S\"\n    lat_end = f\"{lat_end}N\" if lat_end >= 0 else f\"{abs(lat_end)}S\"\n    return f\"{lat_start}-{lat_end}\"\n  ",
  "history_output" : "",
  "history_begin_time" : 1670331423546,
  "history_end_time" : 1670331426665,
  "history_notes" : null,
  "history_process" : "4o6voy",
  "host_id" : "100001",
  "indicator" : "Done"
}]
